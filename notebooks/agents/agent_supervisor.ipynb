{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph_supervisor import create_supervisor\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Create specialized agents\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\"\"\"\n",
    "    return (\n",
    "        \"Here are the headcounts for each of the FAANG companies in 2024:\\n\"\n",
    "        \"1. **Facebook (Meta)**: 67,317 employees.\\n\"\n",
    "        \"2. **Apple**: 164,000 employees.\\n\"\n",
    "        \"3. **Amazon**: 1,551,000 employees.\\n\"\n",
    "        \"4. **Netflix**: 14,000 employees.\\n\"\n",
    "        \"5. **Google (Alphabet)**: 181,269 employees.\"\n",
    "    )\n",
    "\n",
    "math_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[add, multiply],\n",
    "    name=\"math_expert\",\n",
    "    prompt=\"You are a math expert. Always use one tool at a time.\"\n",
    ")\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[web_search],\n",
    "    name=\"research_expert\",\n",
    "    prompt=\"You are a world class researcher with access to web search. Do not do any math.\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = create_supervisor(\n",
    "    [research_agent, math_agent],\n",
    "    model=model,\n",
    "    prompt=(\n",
    "        \"You are a team supervisor managing a research expert and a math expert. \"\n",
    "        \"For current events, use research_agent. \"\n",
    "        \"For math problems, use math_agent.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()\n",
    "result = app.invoke({\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"which is the square root of 16?\"\n",
    "        }\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervisor: The square root of 16 is 4.\n"
     ]
    }
   ],
   "source": [
    "agent_name = result[\"messages\"][-1].name\n",
    "message = result[\"messages\"][-1].content\n",
    "\n",
    "print(f\"{agent_name}: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervisor Agent with low level agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# --- Weather tool ---\n",
    "@tool\n",
    "def get_weather(location: str):\n",
    "    \"\"\"Call to get the current weather.\"\"\"\n",
    "    if location.lower() in [\"munich\"]:\n",
    "        return \"It's 15 degrees Celsius and cloudy.\"\n",
    "    else:\n",
    "        return \"It's 32 degrees Celsius and sunny.\"\n",
    "\n",
    "# We'll create a model and bind the tool so the LLM knows it can call `get_weather`.\n",
    "tools = [get_weather]\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\").bind_tools(tools)\n",
    "\n",
    "# --- Existing agent workflow definition ---\n",
    "def call_model(state: MessagesState):\n",
    "    \"\"\"Call the LLM with the conversation so far.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    \"\"\"If there's a tool call requested, go to 'tools', else end.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "weather_workflow = StateGraph(MessagesState)\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "weather_workflow.add_node(\"agent\", call_model)\n",
    "weather_workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "weather_workflow.add_edge(START, \"agent\")\n",
    "weather_workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "weather_workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "weather_agent_graph =  weather_workflow.compile(name=\"weather_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "\n",
    "supervisor_workflow = create_supervisor(\n",
    "    agents=[weather_agent_graph],\n",
    "    model=model,\n",
    "    prompt=(\n",
    "        \"You are a supervisor managing a weather agent. \"\n",
    "        \"For any weather-related question, call the 'weather_agent' to handle it.\"\n",
    "    ),\n",
    "    output_mode=\"last_message\",\n",
    "    #output_mode=\"full_history\",\n",
    "    supervisor_name=\"supervisor_agent\",\n",
    ")\n",
    "\n",
    "supervisor_app = supervisor_workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm here and ready to assist you. How can I help you today?\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = supervisor_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hello there, how are you?\")]}\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in Munich is currently 15 degrees Celsius and cloudy. If you have any further questions, feel free to ask!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = supervisor_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"How is the weather in Munich?\")]}\n",
    ")\n",
    "result[\"messages\"][-1].content\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
